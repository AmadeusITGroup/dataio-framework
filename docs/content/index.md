---
title: Home
layout: home
nav_order: 1
---
# Data I/O

Automated handling of inputs and outputs through a unified interface.
{: .fs-6}
{: .fw-300} 

[Get started](getting-started.html){: .btn .btn-purple } [View it on GitHub](https://github.com/AmadeusITGroup/conf4dataio){: .btn }

--- 

Welcome to the Data I/O documentation! 

Data I/O is a Spark SQL Scala framework automating the process of reading and writing data. It gives you the tools to
write ETL pipelines by focusing on the transformation of the data, regardless of its origin or destination.

Be sure to check out the [getting started](getting-started.html) page for an overview of Data I/O's features, or visit the [main concepts page](main-concepts.html) for a deeper dive.

If you know your way around Data I/O and want to learn how to create your own pipes, head to
the [advanced section](advanced/advanced.html).
